@inproceedings{Cusumano-Towner:2019,
 author = {Cusumano-Towner, Marco F. and Saad, Feras A. and Lew, Alexander K. and Mansinghka, Vikash K.},
 title = {Gen: A General-purpose Probabilistic Programming System with Programmable Inference},
 booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
 series = {PLDI 2019},
 year = {2019},
 isbn = {978-1-4503-6712-7},
 location = {Phoenix, AZ, USA},
 pages = {221--236},
 numpages = {16},
 url = {http://doi.acm.org/10.1145/3314221.3314642},
 doi = {10.1145/3314221.3314642},
 acmid = {3314642},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Markov chain Monte Carlo, Probabilistic programming, sequential Monte Carlo, variational inference},
} 

@software{Blaom:2019,
  author       = {Anthony Blaom and
                  Franz Kiraly and
                  Thibaut Lienart and
                  Sebastian Vollmer},
  title        = {alan-turing-institute/MLJ.jl: v0.5.3},
  month        = nov,
  year         = 2019,
  publisher    = {Zenodo},
  version      = {v0.5.3},
  doi          = {10.5281/zenodo.3541506},
  url          = {https://doi.org/10.5281/zenodo.3541506}
}

@article{Meurer:2017,
 title = {SymPy: symbolic computing in Python},
 author = {Meurer, Aaron and Smith, Christopher P. and Paprocki, Mateusz and \v{C}ert\'{i}k, Ond\v{r}ej and Kirpichev, Sergey B. and Rocklin, Matthew and Kumar, AMiT and Ivanov, Sergiu and Moore, Jason K. and Singh, Sartaj and Rathnayake, Thilina and Vig, Sean and Granger, Brian E. and Muller, Richard P. and Bonazzi, Francesco and Gupta, Harsh and Vats, Shivam and Johansson, Fredrik and Pedregosa, Fabian and Curry, Matthew J. and Terrel, Andy R. and Rou\v{c}ka, \v{S}t\v{e}p\'{a}n and Saboo, Ashutosh and Fernando, Isuru and Kulal, Sumith and Cimrman, Robert and Scopatz, Anthony},
 year = 2017,
 month = jan,
 keywords = {Python, Computer algebra system, Symbolics},
 abstract = {
            SymPy is an open source computer algebra system written in pure Python. It is built with a focus on extensibility and ease of use, through both interactive and programmatic applications. These characteristics have led SymPy to become a popular symbolic library for the scientific Python ecosystem. This paper presents the architecture of SymPy, a description of its features, and a discussion of select submodules. The supplementary material provide additional examples and further outline details of the architecture and features of SymPy.
         },
 volume = 3,
 pages = {e103},
 journal = {PeerJ Computer Science},
 issn = {2376-5992},
 url = {https://doi.org/10.7717/peerj-cs.103},
 doi = {10.7717/peerj-cs.103}
}

@inproceedings{ge2018t,
  author    = {Hong Ge and
               Kai Xu and
               Zoubin Ghahramani},
  title     = {Turing: a language for flexible probabilistic inference},
  booktitle = {International Conference on Artificial Intelligence and Statistics,
               {AISTATS} 2018, 9-11 April 2018, Playa Blanca, Lanzarote, Canary Islands,
               Spain},
  pages     = {1682--1690},
  year      = {2018},
  url       = {http://proceedings.mlr.press/v84/ge18b.html},
  biburl    = {https://dblp.org/rec/bib/conf/aistats/GeXG18},
}

@article{arviz_2019,
        title = {{ArviZ} a unified library for exploratory analysis of {Bayesian} models in {Python}},
        author = {Kumar, Ravin and Carroll, Colin and Hartikainen, Ari and Martin, Osvaldo A.},
        journal = {The Journal of Open Source Software},
        year = {2019},
        doi = {10.21105/joss.01143},
        url = {http://joss.theoj.org/papers/10.21105/joss.01143},
}

@misc{Distributions.jl-2019,
  author       = {Dahua Lin and
                  John Myles White and
                  Simon Byrne and
                  Douglas Bates and
                  Andreas Noack and
                  John Pearson and
                  Alex Arslan and
                  Kevin Squire and
                  David Anthoff and
                  Theodore Papamarkou and
                  Mathieu Besançon and
                  Jan Drugowitsch and
                  Moritz Schauer and
                  other contributors},
  title        = {{JuliaStats/Distributions.jl: a Julia package for probability distributions and associated functions}},
  month        = july,
  year         = 2019,
  doi          = {10.5281/zenodo.2647458},
  url          = {https://doi.org/10.5281/zenodo.2647458}
}

@article{Julia-2017,
    title={Julia: A fresh approach to numerical computing},
    author={Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B},
    journal={SIAM {R}eview},
    volume={59},
    number={1},
    pages={65--98},
    year={2017},
    publisher={SIAM},
    doi={10.1137/141000671}
}

@article{10.7717/peerj-cs.103,
 title = {SymPy: symbolic computing in Python},
 author = {Meurer, Aaron and Smith, Christopher P. and Paprocki, Mateusz and \v{C}ert\'{i}k, Ond\v{r}ej and Kirpichev, Sergey B. and Rocklin, Matthew and Kumar, AMiT and Ivanov, Sergiu and Moore, Jason K. and Singh, Sartaj and Rathnayake, Thilina and Vig, Sean and Granger, Brian E. and Muller, Richard P. and Bonazzi, Francesco and Gupta, Harsh and Vats, Shivam and Johansson, Fredrik and Pedregosa, Fabian and Curry, Matthew J. and Terrel, Andy R. and Rou\v{c}ka, \v{S}t\v{e}p\'{a}n and Saboo, Ashutosh and Fernando, Isuru and Kulal, Sumith and Cimrman, Robert and Scopatz, Anthony},
 year = 2017,
 month = jan,
 keywords = {Python, Computer algebra system, Symbolics},
 abstract = {
            SymPy is an open source computer algebra system written in pure Python. It is built with a focus on extensibility and ease of use, through both interactive and programmatic applications. These characteristics have led SymPy to become a popular symbolic library for the scientific Python ecosystem. This paper presents the architecture of SymPy, a description of its features, and a discussion of select submodules. The supplementary material provide additional examples and further outline details of the architecture and features of SymPy.
         },
 volume = 3,
 pages = {e103},
 journal = {PeerJ Computer Science},
 issn = {2376-5992},
 url = {https://doi.org/10.7717/peerj-cs.103},
 doi = {10.7717/peerj-cs.103}
}

@inproceedings{narayanan2016probabilistic,
    title = {Probabilistic inference by program transformation in Hakaru (system description)},
    author = {Narayanan, Praveen and Carette, Jacques and Romano, Wren and Shan, Chung{-}chieh and Zinkov, Robert},
    booktitle = {International Symposium on Functional and Logic Programming - 13th International Symposium, {FLOPS} 2016, Kochi, Japan, March 4-6, 2016, Proceedings},
    pages = {62--79},
    year = {2016},
    organization = {Springer},
    url = {http://dx.doi.org/10.1007/978-3-319-29604-3_5},
    doi = {10.1007/978-3-319-29604-3_5},
}

@inproceedings{Scherrer2012,
    author = {Scherrer, Chad and Diatchki, Iavor and Erk{\"{o}}k, Levent and Sottile, Matthew},
    booktitle = {Neural Information Processing Systems workshop on Probabilistic Programming},
    file = {:home/chad/Dropbox/DropsyncFiles/Mendeley/Scherrer et al. - 2012 - Passage A Parallel Sampler Generator for Hierarchical Bayesian Modeling.pdf:pdf},
    mendeley-groups = {tcp,Zotero - fromMendeley,Zotero - Zotero Library},
    pages = {1--4},
    title = {{Passage : A Parallel Sampler Generator for Hierarchical Bayesian Modeling}},
    year = {2012}
}

@article{stan:2017,
   author = {Bob Carpenter and Andrew Gelman and Matthew Hoffman
             and Daniel Lee and Ben Goodrich and Michael Betancourt
             and Marcus Brubaker and Jiqiang Guo and Peter Li
             and Allen Riddell},
   title = {Stan: {A} Probabilistic Programming Language},
   journal = {Journal of Statistical Software},
   volume = {76},
   number = {1},
   year = {2017}
}

@misc{bezanson2012julia,
    title={Julia: A Fast Dynamic Language for Technical Computing},
    author={Jeff Bezanson and Stefan Karpinski and Viral B. Shah and Alan Edelman},
    year={2012},
    eprint={1209.5145},
    archivePrefix={arXiv},
    primaryClass={cs.PL}
}

@article{Douc2005,
abstract = {This contribution is devoted to the comparison of various resampling approaches that have been proposed in the literature on particle filtering. It is first shown using simple arguments that the so-called residual and stratified methods do yield an improvement over the basic multinomial resampling approach. A simple counter-example showing that this property does not hold true for systematic resampling is given. Finally, some results on the large-sample behavior of the simple bootstrap filter algorithm are given. In particular, a central limit theorem is established for the case where resampling is performed using the residual approach.},
archivePrefix = {arXiv},
arxivId = {cs/0507025},
author = {Douc, Randal and Capp{\'{e}}, Olivier and Moulines, Eric},
doi = {10.1109/ispa.2005.195385},
eprint = {0507025},
file = {:home/chad/Dropbox/DropsyncFiles/Mendeley/Douc, Capp, Moulines - 2016 - Comparison of Resampling Schemes for Particle Filtering.pdf:pdf},
isbn = {953184089X},
journal = {Image and Signal Processing and Analysis, 2005. ISPA 2005. Proceedings of the 4th International Symposium},
pages = {64--69},
primaryClass = {cs},
title = {{Comparison of resampling schemes for particle filtering}},
volume = {2005},
year = {2005}
}

@article{Neal2011,
abstract = {Hamiltonian dynamics can be used to produce distant proposals for the Metropolis algorithm, thereby avoiding the slow exploration of the state space that results from the diffusive behaviour of simple random-walk proposals. Though originating in physics, Hamiltonian dynamics can be applied to most problems with continuous state spaces by simply introducing fictitious "momentum" variables. A key to its usefulness is that Hamiltonian dynamics preserves volume, and its trajectories can thus be used to define complex mappings without the need to account for a hard-to-compute Jacobian factor - a property that can be exactly maintained even when the dynamics is approximated by discretizing time. In this review, I discuss theoretical and practical aspects of Hamiltonian Monte Carlo, and present some of its variations, including using windows of states for deciding on acceptance or rejection, computing trajectories using fast approximations, tempering during the course of a trajectory to handle isolated modes, and short-cut methods that prevent useless trajectories from taking much computation time.},
archivePrefix = {arXiv},
arxivId = {1206.1901},
author = {Neal, Radford M.},
doi = {10.1201/b10905-6},
eprint = {1206.1901},
file = {:home/chad/Dropbox/DropsyncFiles/Mendeley//Neal - 2011 - MCMC using hamiltonian dynamics.pdf:pdf},
isbn = {9781420079425},
journal = {Handbook of Markov Chain Monte Carlo},
mendeley-groups = {Zotero - fromMendeley,Zotero - Zotero Library},
pages = {113--162},
title = {{MCMC using hamiltonian dynamics}},
url = {http://arxiv.org/abs/1206.1901},
year = {2011}
}

@article{Pearl1995,
abstract = {The primary aim of this paper is to show how graphical models can be used as a mathematical language for integrating statistical and subject-matter information. In particular, the paper develops a principled, nonparametric framework for causal inference, in which diagrams are queried to determine if the assumptions available are sufficient for identifying causal effects from nonexperimental data. If so the diagrams can be queried to produce mathematical expressions for causal effects in terms of observed distributions; otherwise, the diagrams can be queried to suggest additional observations or auxiliary experiments from which the desired inferences can be obtained.},
author = {Pearl, Judea},
file = {:home/chad/Dropbox/DropsyncFiles/Mendeley/Pearl - 1995 - Causal Diagrams of Empirical Research.pdf:pdf},
journal = {Biometrika},
number = {4},
pages = {669--688},
title = {{Causal Diagrams of Empirical Research}},
url = {https://escholarship.org/content/qt6gv9n38c/qt6gv9n38c.pdf},
volume = {82},
year = {1995}
}

@software{tamas_k_papp_2019_3590018,
  author       = {Tamas K. Papp and
                  Morten Piibeleht},
  title        = {tpapp/DynamicHMC.jl: v2.1.2},
  month        = dec,
  year         = 2019,
  publisher    = {Zenodo},
  version      = {v2.1.2},
  doi          = {10.5281/zenodo.3590018},
  url          = {https://doi.org/10.5281/zenodo.3590018}
}

@Misc{SimpleWorld,
  key = 	 {SimpleWorld},
  year = 2019,
  author = 	 {Edward Scheinerman},
  title = 	 {\texttt{SimpleWorld} {J}ulia module},
  howpublished = {\url{github.com/scheinerman/SimpleWorld.jl}}
}

@misc{8ff6a743-0ad6-4d98-bbb3-5d549c698bc1,
  abstract     = {This package facilitates working with probability distributions by means of Monte-Carlo methods, in a way that allows for propagation of probability distributions through functions. This is useful for, e.g., nonlinear uncertainty propagation. A variable or parameter might be associated with uncertainty if it is measured or otherwise estimated from data. We provide two core types to represent probability distributions: Particles and StaticParticles, both &lt;: Real. (The name "Particles" comes from the particle-filtering literature.) These types all form a Monte-Carlo approximation of the distribution of a floating point number, i.e., the distribution is represented by samples/particles. Correlated quantities are handled as well, see multivariate particles below.<br>
<br>
Although several interesting use cases for doing calculations with probability distributions have popped up (see Examples), the original goal of the package is similar to that of Measurements.jl, to propagate the uncertainty from input of a function to the output. The difference compared to a Measurement is that Particles represent the distribution using a vector of unweighted particles, and can thus represent arbitrary distributions and handle nonlinear uncertainty propagation well. Functions like f(x) = x², f(x) = sign(x) at x=0 and long-time integration, are examples that are not handled well using linear uncertainty propagation ala Measurements.jl. MonteCarloMeasurements also support correlations between quantities.<br>
<br>
A number of type Particles behaves just as any other Number while partaking in calculations. After a calculation, an approximation to the complete distribution of the output is captured and represented by the output particles. mean, std etc. can be extracted from the particles using the corresponding functions. Particles also interact with Distributions.jl, so that you can call, e.g., Normal(p) and get back a Normal type from distributions or fit(Gamma, p) to get a Gammadistribution. Particles can also be iterated, asked for maximum/minimum, quantile etc. If particles are plotted with plot(p), a histogram is displayed. This requires Plots.jl. A kernel-density estimate can be obtained by density(p) is StatsPlots.jl is loaded.},
  author       = {Bagge Carlson, Fredrik},
  language     = {eng},
  month        = {04},
  publisher    = {github},
  title        = {MonteCarloMeasurements.jl : Propagation of distributions by Monte-Carlo sampling: Real number types with uncertainty represented by particle clouds.},
  url          = {https://github.com/baggepinnen/MonteCarloMeasurements.jl},
  year         = {2019},
}